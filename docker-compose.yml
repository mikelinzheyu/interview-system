# AI面试系统 - 生产环境 Docker Compose 配置
# ================================================
version: '3.8'

services:
  # Mock API 后端服务 (使用Alpine作为基础镜像)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    image: interview-system/backend:latest
    container_name: interview-backend
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3001
      TZ: ${TZ:-Asia/Shanghai}
      DIFY_API_KEY: ${DIFY_API_KEY}
      DIFY_API_BASE_URL: ${DIFY_API_BASE_URL}
      DIFY_WORKFLOW_URL: ${DIFY_WORKFLOW_URL}
      REDIS_HOST: ${REDIS_HOST:-interview-redis}
      REDIS_PORT: ${REDIS_PORT:-6379}
      REDIS_DB: ${REDIS_DB:-0}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    expose:
      - "3001"
    ports:
      - "${BACKEND_PORT:-8080}:3001"
    volumes:
      - ./logs/backend:/app/logs
      - ./backend/uploads:/app/uploads
    networks:
      - interview-network
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # 前端 Nginx 服务
  frontend:
    image: flowork-frontend-local:latest
    container_name: interview-frontend
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-80}:80"
      - "${FRONTEND_HTTPS_PORT:-443}:443"
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./logs/frontend:/var/log/nginx
    networks:
      - interview-network
    environment:
      TZ: ${TZ:-Asia/Shanghai}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis 缓存服务 (生产环境推荐启用)
  redis:
    image: redis:7-alpine
    container_name: interview-redis
    restart: unless-stopped
    environment:
      TZ: ${TZ:-Asia/Shanghai}
    command: >
      redis-server
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec
    volumes:
      - redis_data:/data
      - ./logs/redis:/var/log/redis
    expose:
      - "6379"
    ports:
      - "${REDIS_PORT:-6379}:6379"
    networks:
      - interview-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # 工作流存储服务 (Workflows Storage Service) - 独立 Java 容器
  storage-service:
    build:
      context: ./storage-service
      dockerfile: Dockerfile.prod
      args:
        - BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
        - VCS_REF=latest
    image: interview-system/storage-service:latest
    container_name: interview-storage-service
    restart: unless-stopped

    # 环境变量配置
    environment:
      # Java 配置
      JAVA_OPTS: "-Xms256m -Xmx512m -XX:+UseG1GC -XX:MaxGCPauseMillis=200"
      SPRING_PROFILES_ACTIVE: prod
      SERVER_PORT: 8081

      # Redis 连接配置
      SPRING_REDIS_HOST: ${REDIS_HOST:-interview-redis}
      SPRING_REDIS_PORT: ${REDIS_PORT:-6379}
      SPRING_REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      SPRING_REDIS_DATABASE: ${REDIS_DB:-0}
      SPRING_REDIS_TIMEOUT: 3000ms
      SPRING_REDIS_LETTUCE_POOL_MAX_ACTIVE: "20"
      SPRING_REDIS_LETTUCE_POOL_MAX_IDLE: "10"
      SPRING_REDIS_LETTUCE_POOL_MIN_IDLE: "5"

      # API 密钥配置
      SESSION_STORAGE_API_KEY: ${SESSION_STORAGE_API_KEY:-ak_live_a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0}

      # 日志配置
      LOGGING_LEVEL_COM_EXAMPLE_INTERVIEWSTORAGE: INFO
      LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_SECURITY: WARN
      LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_DATA_REDIS: INFO

      # 时区和地域配置
      TZ: ${TZ:-Asia/Shanghai}
      SPRING_JACKSON_TIME_ZONE: Asia/Shanghai
      SPRING_JACKSON_LOCALE: zh_CN

    # 暴露端口
    expose:
      - "8081"
    ports:
      - "${STORAGE_PORT:-8081}:8081"

    # 数据卷挂载
    volumes:
      - storage-logs:/app/logs
      - storage-data:/app/data
      - ./logs/storage:/app/logs/host

    # 网络配置
    networks:
      - interview-network

    # 依赖关系
    depends_on:
      redis:
        condition: service_healthy

    # 健康检查
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/api/sessions"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

    # 日志驱动配置
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
        labels: "service=storage-service"

  # Nginx 反向代理 (生产环境推荐)
  nginx-proxy:
    image: nginx:alpine
    container_name: interview-proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/proxy.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/proxy:/var/log/nginx
    depends_on:
      frontend:
        condition: service_healthy
      backend:
        condition: service_healthy
    networks:
      - interview-network
    environment:
      TZ: ${TZ:-Asia/Shanghai}
    profiles:
      - proxy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Cloudflare Tunnel 服务 (替代 ngrok)
  cloudflare-tunnel:
    image: cloudflare/cloudflared:latest
    container_name: interview-cloudflare-tunnel
    restart: unless-stopped

    # 使用配置文件启动隧道
    command: tunnel --config /etc/cloudflared/config.yml run

    # 环境变量
    environment:
      TZ: ${TZ:-Asia/Shanghai}
      TUNNEL_TOKEN: ${CLOUDFLARE_TUNNEL_TOKEN:-}

    # 挂载配置文件和凭证
    volumes:
      - ./cloudflare-tunnel/config.yml:/etc/cloudflared/config.yml:ro
      - ./cloudflare-tunnel/credentials.json:/etc/cloudflared/credentials.json:ro
      - ./logs/tunnel:/var/log/cloudflared

    # 网络配置 (连接到 interview-network)
    networks:
      - interview-network

    # 依赖后端服务启动
    depends_on:
      backend:
        condition: service_healthy
      storage-service:
        condition: service_healthy

    # 健康检查 (检查日志文件是否存在)
    healthcheck:
      test: ["CMD", "sh", "-c", "pgrep cloudflared || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

    # 日志配置
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    # 可选: 如果不需要 Cloudflare Tunnel,可以禁用此服务
    # profiles:
    #   - tunnel

# 数据卷定义
volumes:
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/redis

  # Storage Service 数据卷
  storage-logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./logs/storage

  storage-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/storage

# 网络配置
networks:
  interview-network:
    driver: bridge