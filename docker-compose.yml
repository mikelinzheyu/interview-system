# AI面试系统 - 生产环境 Docker Compose 配置
# ================================================
version: '3.8'

services:
  # Mock API 后端服务 (使用Alpine作为基础镜像)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    image: interview-system/backend:latest
    container_name: interview-backend
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3001
      TZ: ${TZ:-Asia/Shanghai}
      DIFY_API_KEY: ${DIFY_API_KEY}
      DIFY_API_BASE_URL: ${DIFY_API_BASE_URL}
      DIFY_WORKFLOW_URL: ${DIFY_WORKFLOW_URL}
      REDIS_HOST: interview-redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      REDIS_DB: ${REDIS_DB:-0}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    expose:
      - "3001"
    ports:
      - "${BACKEND_PORT:-8080}:3001"
    volumes:
      - ./logs/backend:/app/logs
      - ./backend/uploads:/app/uploads
    networks:
      - interview-network
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # 前端 Nginx 服务
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        VITE_API_BASE_URL: ${VITE_API_BASE_URL:-/api}
    image: interview-system/frontend:latest
    container_name: interview-frontend
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-80}:80"
      - "${FRONTEND_HTTPS_PORT:-443}:443"
    depends_on:
      backend:
        condition: service_healthy
    volumes:
      - ./logs/frontend:/var/log/nginx
    networks:
      - interview-network
    environment:
      TZ: ${TZ:-Asia/Shanghai}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis 缓存服务 (生产环境推荐启用)
  redis:
    image: redis:7-alpine
    container_name: interview-redis
    restart: unless-stopped
    environment:
      TZ: ${TZ:-Asia/Shanghai}
    command: >
      redis-server
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec
    volumes:
      - redis_data:/data
      - ./logs/redis:/var/log/redis
    expose:
      - "6379"
    ports:
      - "${REDIS_PORT:-6379}:6379"
    networks:
      - interview-network
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 20
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Nginx 反向代理 (生产环境推荐)
  nginx-proxy:
    image: nginx:alpine
    container_name: interview-proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/proxy.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/proxy:/var/log/nginx
    depends_on:
      frontend:
        condition: service_healthy
      backend:
        condition: service_healthy
    networks:
      - interview-network
    environment:
      TZ: ${TZ:-Asia/Shanghai}
    profiles:
      - proxy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"


# 数据卷定义
volumes:
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/redis

# 网络配置
networks:
  interview-network:
    driver: bridge