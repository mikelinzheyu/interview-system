<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>åŠŸèƒ½è‡ªæ£€ - æ‘„åƒå¤´/è¯­éŸ³è¯†åˆ«/API å¥åº·æ£€æŸ¥</title>
  <style>
    body { font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, 'Helvetica Neue', Arial, 'Noto Sans', 'Noto Sans CJK SC', 'PingFang SC', 'Microsoft YaHei', sans-serif; margin: 0; padding: 24px; background: #f7f8fa; color: #1f2937; }
    h1 { margin: 0 0 16px; }
    .test-section { background: #fff; border: 1px solid #e5e7eb; border-radius: 12px; padding: 16px; margin: 16px 0; }
    .test-title { margin: 0 0 12px; }
    .test-controls { display: flex; flex-wrap: wrap; gap: 8px; margin-bottom: 8px; }
    button { padding: 8px 12px; border: 1px solid #e5e7eb; background: #f3f4f6; border-radius: 8px; cursor: pointer; }
    button:hover { background: #e5e7eb; }
    .result-area { white-space: pre-wrap; background: #f9fafb; border: 1px dashed #e5e7eb; padding: 10px; border-radius: 8px; color: #111827; }
    video { width: 100%; max-width: 520px; border-radius: 8px; border: 1px solid #e5e7eb; }
    .status { color: #047857 }
    .error { color: #b91c1c }
  </style>
</head>
<body>
  <h1>ğŸ§ª åŠŸèƒ½è‡ªæ£€</h1>

  <!-- æ‘„åƒå¤´æµ‹è¯• -->
  <div class="test-section">
    <h2 class="test-title">ğŸ“¹ æ‘„åƒå¤´åŠŸèƒ½æµ‹è¯•</h2>
    <div class="test-controls">
      <button onclick="startCamera()">å¯åŠ¨æ‘„åƒå¤´</button>
      <button onclick="stopCamera()">åœæ­¢æ‘„åƒå¤´</button>
      <button onclick="checkCameraSupport()">æ£€æŸ¥æ”¯æŒæƒ…å†µ</button>
    </div>
    <video id="videoElement" autoplay muted playsinline></video>
    <div id="cameraStatus" class="result-area">ç­‰å¾…æµ‹è¯•...</div>
  </div>

  <!-- è¯­éŸ³è¯†åˆ«æµ‹è¯• -->
  <div class="test-section">
    <h2 class="test-title">ğŸ¤ è¯­éŸ³è¯†åˆ«åŠŸèƒ½æµ‹è¯•</h2>
    <div class="test-controls">
      <button onclick="startSpeechRecognition()">å¼€å§‹è¯­éŸ³è¯†åˆ«</button>
      <button onclick="stopSpeechRecognition()">åœæ­¢è¯­éŸ³è¯†åˆ«</button>
      <button onclick="checkSpeechSupport()">æ£€æŸ¥æ”¯æŒæƒ…å†µ</button>
    </div>
    <div id="speechResult" class="result-area">ç­‰å¾…è¯­éŸ³è¾“å…¥...</div>
    <div id="speechStatus" class="result-area">çŠ¶æ€ï¼šæœªå¼€å¯</div>
  </div>

  <!-- API å¥åº·æ£€æŸ¥ -->
  <div class="test-section">
    <h2 class="test-title">ğŸ©º API å¥åº·æ£€æŸ¥</h2>
    <div class="test-controls">
      <button onclick="testHealthCheck()">æµ‹è¯•å¥åº·æ£€æŸ¥</button>
    </div>
    <div id="healthResult" class="result-area">ç­‰å¾…æµ‹è¯•...</div>
  </div>

  <!-- æ±‡æ€»æµ‹è¯• -->
  <div class="test-section">
    <h2 class="test-title">ğŸ“‹ ä¸€é”®å®Œæ•´æµ‹è¯•</h2>
    <div class="test-controls">
      <button onclick="runFullTest()">å¼€å§‹è¿è¡Œå®Œæ•´åŠŸèƒ½æµ‹è¯•..</button>
    </div>
    <div id="fullTestResult" class="result-area">ç­‰å¾…æµ‹è¯•...</div>
  </div>

  <script>
    const videoEl = document.getElementById('videoElement');
    const setText = (id, text, cls='') => { const el = document.getElementById(id); el.textContent = text; el.className = `result-area ${cls}` }

    // æ‘„åƒå¤´
    let mediaStream;
    async function startCamera() {
      try {
        setText('cameraStatus', 'æ­£åœ¨å¯åŠ¨æ‘„åƒå¤´..', 'status')
        mediaStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false })
        videoEl.srcObject = mediaStream
        setText('cameraStatus', 'âœ… æ‘„åƒå¤´å¯åŠ¨æˆåŠŸ', 'status')
      } catch (e) {
        setText('cameraStatus', `âŒ æ‘„åƒå¤´å¯åŠ¨å¤±è´¥: ${e.message}`, 'error')
      }
    }
    function stopCamera() {
      if (mediaStream) {
        mediaStream.getTracks().forEach(t => t.stop())
        videoEl.srcObject = null
      }
      setText('cameraStatus', 'â¹ï¸ æ‘„åƒå¤´å·²åœæ­¢', 'status')
    }
    function checkCameraSupport() {
      const support = {
        mediaDevices: !!navigator.mediaDevices,
        getUserMedia: !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia),
        webRTC: 'RTCPeerConnection' in window
      }
      const text = [
        'ğŸ“‹ æµè§ˆå™¨æ”¯æŒæƒ…å†µ:',
        `- getUserMedia: ${support.getUserMedia ? 'å·²æ”¯æŒ' : 'ä¸æ”¯æŒ'}`,
        `- WebRTC: ${support.webRTC ? 'å·²æ”¯æŒ' : 'ä¸æ”¯æŒ'}`
      ].join('\n')
      setText('cameraStatus', text, support.getUserMedia ? 'status' : 'error')
    }

    // è¯­éŸ³è¯†åˆ«ï¼ˆChrome/Edge å®éªŒæ€§ï¼‰
    let recognition, isListening = false
    function startSpeechRecognition() {
      const SR = window.SpeechRecognition || window.webkitSpeechRecognition
      if (!SR) {
        setText('speechStatus', 'âŒ æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«', 'error')
        return
      }
      recognition = new SR()
      recognition.lang = 'zh-CN'
      recognition.interimResults = true
      recognition.continuous = true

      recognition.onresult = (event) => {
        let finalTranscript = '', interimTranscript = ''
        for (let i = event.resultIndex; i < event.results.length; ++i) {
          const t = event.results[i][0].transcript
          if (event.results[i].isFinal) finalTranscript += t; else interimTranscript += t
        }
        const out = [
          `ğŸ“ å®æ—¶è¯†åˆ«: ${interimTranscript}`,
          finalTranscript ? `âœ… æœ€ç»ˆç»“æœ: ${finalTranscript}` : ''
        ].filter(Boolean).join('\n')
        setText('speechResult', out || 'ç­‰å¾…è¯­éŸ³è¾“å…¥...')
      }
      recognition.onerror = (e) => { setText('speechStatus', `âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯: ${e.error}`, 'error'); isListening = false }
      recognition.onend = () => { setText('speechStatus', 'â¹ï¸ è¯­éŸ³è¯†åˆ«å·²åœæ­¢', 'status'); isListening = false }
      recognition.start(); isListening = true
      setText('speechStatus', 'ğŸ™ï¸ æ­£åœ¨å¬å†™...', 'status')
    }
    function stopSpeechRecognition() { if (recognition && isListening) recognition.stop() }
    function checkSpeechSupport() {
      const supported = !!(window.SpeechRecognition || window.webkitSpeechRecognition)
      const text = [
        'ğŸ“‹ è¯­éŸ³è¯†åˆ«æ”¯æŒæƒ…å†µ:',
        `- Web Speech API: ${supported ? 'å·²æ”¯æŒ' : 'ä¸æ”¯æŒ'}`,
        '- å»ºè®®æµè§ˆå™¨: Chrome, Edge'
      ].join('\n')
      setText('speechStatus', text, supported ? 'status' : 'error')
    }

    // API å¥åº·æ£€æŸ¥
    async function testHealthCheck() {
      try {
        setText('healthResult', 'ğŸ” æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€..', 'status')
        const r = await fetch('/api/health')
        const data = await r.json()
        const text = [
          'âœ… æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡',
          `ğŸ·ï¸ æœåŠ¡: ${data.data?.service || 'mock'}`,
          `ğŸ“Š çŠ¶æ€: ${data.data?.status || 'UP'}`,
          `ğŸ“… æ—¶é—´: ${new Date(data.timestamp || Date.now()).toLocaleString()}`
        ].join('\n')
        setText('healthResult', text, 'status')
      } catch (e) {
        setText('healthResult', `âŒ å¥åº·æ£€æŸ¥å¤±è´¥: ${e.message}`, 'error')
      }
    }

    // æ±‡æ€»æµ‹è¯•
    async function runFullTest() {
      setText('fullTestResult', 'ğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´åŠŸèƒ½æµ‹è¯•..', 'status')
      const tests = [
        { name: 'æµè§ˆå™¨æ”¯æŒæ£€æŸ¥', func: checkCameraSupport },
        { name: 'è¯­éŸ³è¯†åˆ«æ”¯æŒæ£€æŸ¥', func: checkSpeechSupport },
        { name: 'API å¥åº·æ£€æŸ¥', func: testHealthCheck }
      ]
      let results = ['ğŸ” æµ‹è¯•ç»“æœæ±‡æ€»']
      for (const t of tests) {
        try { await t.func(); results.push(`âœ“ ${t.name}: é€šè¿‡`) }
        catch (e) { results.push(`âœ— ${t.name}: å¤±è´¥ - ${e.message}`) }
      }
      results.push('\nğŸ‰ æµ‹è¯•å®Œæˆï¼å¯ä»¥å¼€å§‹ä½¿ç”¨ AI é¢è¯•åŠŸèƒ½')
      setText('fullTestResult', results.join('\n'), 'status')
    }

    document.addEventListener('DOMContentLoaded', () => {
      setText('fullTestResult', 'ğŸ“‹ é¡µé¢åŠ è½½å®Œæˆï¼Œå¯ä»¥å¼€å§‹æµ‹è¯•å„é¡¹åŠŸèƒ½')
    })
  </script>
</body>
</html>