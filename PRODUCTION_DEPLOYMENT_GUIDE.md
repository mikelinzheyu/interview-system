# AIé¢è¯•ç³»ç»Ÿ - ç”Ÿäº§ç¯å¢ƒå…¨Dockeréƒ¨ç½²æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [å‰ç½®æ¡ä»¶](#å‰ç½®æ¡ä»¶)
3. [éƒ¨ç½²æ¶æ„](#éƒ¨ç½²æ¶æ„)
4. [è¯¦ç»†éƒ¨ç½²æ­¥éª¤](#è¯¦ç»†éƒ¨ç½²æ­¥éª¤)
5. [é…ç½®æŒ‡å—](#é…ç½®æŒ‡å—)
6. [ç›‘æ§å’Œæ—¥å¿—](#ç›‘æ§å’Œæ—¥å¿—)
7. [å¤‡ä»½å’Œæ¢å¤](#å¤‡ä»½å’Œæ¢å¤)
8. [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
9. [å®‰å…¨æœ€ä½³å®è·µ](#å®‰å…¨æœ€ä½³å®è·µ)
10. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

---

## å¿«é€Ÿå¼€å§‹

### Linux/Mac (ä½¿ç”¨Bashè„šæœ¬)

```bash
# 1. ç¡®ä¿æœ‰æ‰§è¡Œæƒé™
chmod +x deploy-prod.sh

# 2. è¿è¡Œéƒ¨ç½²è„šæœ¬
./deploy-prod.sh

# 3. ç­‰å¾…éƒ¨ç½²å®Œæˆ
# è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
# - æ£€æŸ¥å‰ç½®æ¡ä»¶
# - åˆ›å»ºå¿…è¦ç›®å½•
# - å¤‡ä»½ç°æœ‰æ•°æ®
# - æ„å»ºé•œåƒ
# - å¯åŠ¨å®¹å™¨
# - éªŒè¯æœåŠ¡
```

### Windows (ä½¿ç”¨Batchè„šæœ¬)

```batch
# 1. å³é”®å•å‡» deploy-prod.bat
# 2. é€‰æ‹© "ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ"
# æˆ–åœ¨å‘½ä»¤è¡Œæ‰§è¡Œï¼š
deploy-prod.bat
```

### æ‰‹åŠ¨éƒ¨ç½²

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd /path/to/interview-system

# 2. å¤åˆ¶ç¯å¢ƒé…ç½®ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
cp .env.docker.example .env.docker

# 3. ç¼–è¾‘ç¯å¢ƒå˜é‡
# ä¿®æ”¹ .env.docker ä¸­çš„æ•æ„Ÿä¿¡æ¯

# 4. åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p logs/{backend,frontend,redis,proxy}
mkdir -p data/{redis,uploads}

# 5. å¯åŠ¨DockeræœåŠ¡
docker-compose up -d

# 6. éªŒè¯æœåŠ¡
docker-compose ps
docker-compose logs -f
```

---

## å‰ç½®æ¡ä»¶

### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux, macOS, æˆ– Windows 10/11 (with WSL2)
- **Docker**: v20.10.0 æˆ–æ›´é«˜
- **Docker Compose**: v2.0.0 æˆ–æ›´é«˜
- **ç£ç›˜ç©ºé—´**: è‡³å°‘ 10GB
- **å†…å­˜**: å»ºè®® 4GB æˆ–ä»¥ä¸Š
- **ç½‘ç»œ**: èƒ½è®¿é—® Docker Hub å’Œ Dify API

### è½¯ä»¶å®‰è£…

#### Docker å®‰è£…

**Ubuntu/Debian:**
```bash
# æ›´æ–°åŒ…ç´¢å¼•
sudo apt-get update

# å®‰è£…ä¾èµ–
sudo apt-get install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

# æ·»åŠ Dockerå®˜æ–¹GPGå¯†é’¥
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# è®¾ç½®ç¨³å®šç‰ˆä»“åº“
echo \
  "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# å®‰è£…Docker
sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# æ·»åŠ å½“å‰ç”¨æˆ·åˆ°dockerç»„
sudo usermod -aG docker $USER

# éªŒè¯å®‰è£…
docker --version
docker-compose --version
```

**CentOS/RHEL:**
```bash
sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
sudo yum install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin
sudo systemctl start docker
sudo systemctl enable docker
```

**macOS:**
```bash
# ä½¿ç”¨Homebrew
brew install docker docker-compose

# æˆ–ä¸‹è½½ Docker Desktop for Mac
# https://www.docker.com/products/docker-desktop
```

**Windows:**
- ä¸‹è½½ [Docker Desktop for Windows](https://www.docker.com/products/docker-desktop)
- å®‰è£…å¹¶å¯ç”¨ WSL2 åç«¯

### éªŒè¯å®‰è£…

```bash
# æ£€æŸ¥Docker
docker --version
docker run hello-world

# æ£€æŸ¥Docker Compose
docker-compose --version

# æ£€æŸ¥ç½‘ç»œè¿æ¥
curl -I https://api.dify.ai
```

---

## éƒ¨ç½²æ¶æ„

### å®¹å™¨ç»„æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ç”Ÿäº§ç¯å¢ƒæ¶æ„                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        Nginx åå‘ä»£ç† (å¯é€‰)                   â”‚   â”‚
â”‚  â”‚  - SSL/TLS ç»ˆæ­¢                              â”‚   â”‚
â”‚  â”‚  - è´Ÿè½½å‡è¡¡                                  â”‚   â”‚
â”‚  â”‚  - æ—¥å¿—è®°å½•                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â†“                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚          Docker Network (Bridge)               â”‚ â”‚
â”‚  â”‚                                                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚   Frontend   â”‚  â”‚   Backend API        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   (Nginx)    â”‚  â”‚   (Node.js)          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚              â”‚  â”‚                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - é¡µé¢æœåŠ¡  â”‚  â”‚  - Mock API          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - é™æ€æ–‡ä»¶  â”‚  â”‚  - WebSocket         â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - åå‘ä»£ç†  â”‚  â”‚  - ä¸šåŠ¡é€»è¾‘          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚              â”‚  â”‚  - æ•°æ®å¤„ç†          â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚         â†“                    â†“                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚ â”‚
â”‚  â”‚  â”‚         Redis Cache              â”‚        â”‚ â”‚
â”‚  â”‚  â”‚  - ä¼šè¯å­˜å‚¨                       â”‚        â”‚ â”‚
â”‚  â”‚  â”‚  - ç¼“å­˜æ•°æ®                       â”‚        â”‚ â”‚
â”‚  â”‚  â”‚  - æ¶ˆæ¯é˜Ÿåˆ—                       â”‚        â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ â”‚
â”‚  â”‚                                                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            æ•°æ®å· (Volumes)                   â”‚  â”‚
â”‚  â”‚  - data/redis (Redis æŒä¹…åŒ–æ•°æ®)             â”‚  â”‚
â”‚  â”‚  - data/uploads (ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶)               â”‚  â”‚
â”‚  â”‚  - logs/* (åº”ç”¨æ—¥å¿—)                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç½‘ç»œæ‹“æ‰‘

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          äº’è”ç½‘ / ç”¨æˆ·                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         [80/443] ç«¯å£
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Nginx ä»£ç†    â”‚
        â”‚ (å¯é€‰)         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        [Docker Bridge Network]
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚            â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
â”‚å‰ç«¯  â”‚  â”‚åç«¯API â”‚  â”‚ Redis  â”‚
â”‚:80  â”‚  â”‚:3001  â”‚  â”‚:6379   â”‚
â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## è¯¦ç»†éƒ¨ç½²æ­¥éª¤

### æ­¥éª¤ 1: ç¯å¢ƒå‡†å¤‡

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir -p /opt/interview-system
cd /opt/interview-system

# å…‹éš†æˆ–æ‹·è´é¡¹ç›®æ–‡ä»¶
git clone <your-repo-url> .
# æˆ–
cp -r /path/to/local/project .

# éªŒè¯å¿…è¦æ–‡ä»¶å­˜åœ¨
ls -la docker-compose.yml
ls -la .env.docker
ls -la backend/Dockerfile
ls -la frontend/Dockerfile
```

### æ­¥éª¤ 2: ç¯å¢ƒé…ç½®

```bash
# ç¼–è¾‘ç¯å¢ƒé…ç½®æ–‡ä»¶
nano .env.docker

# å…³é”®é…ç½®é¡¹ï¼ˆå¿…é¡»ä¿®æ”¹ï¼‰ï¼š
# 1. DIFY_API_KEY: æ›¿æ¢ä¸ºå®é™…çš„Dify APIå¯†é’¥
# 2. DIFY_API_BASE_URL: ç¡®è®¤Dify APIåœ°å€
# 3. JWT_SECRET: ä¿®æ”¹ä¸ºå¼ºå¯†é’¥
# 4. FRONTEND_PORT: å‰ç«¯ç«¯å£ï¼ˆé»˜è®¤80ï¼‰
# 5. BACKEND_PORT: åç«¯ç«¯å£ï¼ˆé»˜è®¤8080ï¼‰
```

### æ­¥éª¤ 3: åˆ›å»ºå¿…è¦ç›®å½•å’Œæ–‡ä»¶

```bash
# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs/{backend,frontend,redis,proxy}

# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/{redis,uploads}

# åˆ›å»ºnginxé…ç½®ç›®å½•
mkdir -p nginx/ssl

# è®¾ç½®æƒé™
chmod -R 755 logs/
chmod -R 755 data/
```

### æ­¥éª¤ 4: SSLè¯ä¹¦é…ç½®ï¼ˆå¯é€‰ä½†æ¨èï¼‰

```bash
# ç”Ÿæˆè‡ªç­¾åè¯ä¹¦ï¼ˆç”¨äºæµ‹è¯•ï¼‰
cd nginx/ssl
openssl req -x509 -newkey rsa:2048 \
  -keyout key.pem -out cert.pem \
  -days 365 -nodes \
  -subj "/C=CN/ST=Beijing/L=Beijing/O=Interview/CN=localhost"
cd ../..

# æˆ–ä½¿ç”¨Let's Encryptï¼ˆæ¨èç”¨äºç”Ÿäº§ï¼‰
sudo apt-get install certbot python3-certbot-nginx
sudo certbot certonly --standalone -d your-domain.com
# å¤åˆ¶è¯ä¹¦åˆ° nginx/ssl/
sudo cp /etc/letsencrypt/live/your-domain.com/fullchain.pem nginx/ssl/cert.pem
sudo cp /etc/letsencrypt/live/your-domain.com/privkey.pem nginx/ssl/key.pem
```

### æ­¥éª¤ 5: æ„å»ºå¹¶å¯åŠ¨å®¹å™¨

```bash
# æ–¹å¼1: ä½¿ç”¨éƒ¨ç½²è„šæœ¬ï¼ˆæ¨èï¼‰
chmod +x deploy-prod.sh
./deploy-prod.sh

# æ–¹å¼2: æ‰‹åŠ¨æ“ä½œ
# 1. åœæ­¢ç°æœ‰å®¹å™¨
docker-compose down

# 2. æ„å»ºé•œåƒ
docker-compose build --no-cache

# 3. å¯åŠ¨å®¹å™¨
docker-compose up -d

# 4. éªŒè¯å®¹å™¨çŠ¶æ€
docker-compose ps
```

### æ­¥éª¤ 6: éªŒè¯éƒ¨ç½²

```bash
# æ£€æŸ¥å®¹å™¨è¿è¡ŒçŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# æµ‹è¯•å‰ç«¯æœåŠ¡
curl http://localhost:80

# æµ‹è¯•åç«¯API
curl http://localhost:8080/api/health

# æµ‹è¯•Redis
docker-compose exec redis redis-cli ping
```

---

## é…ç½®æŒ‡å—

### ç¯å¢ƒå˜é‡è¯¦è§£

```env
# åº”ç”¨ä¿¡æ¯
APP_NAME=AIé¢è¯•ç³»ç»Ÿ                    # åº”ç”¨åç§°
APP_VERSION=1.0.0                      # ç‰ˆæœ¬
APP_ENV=production                     # ç¯å¢ƒæ ‡è¯†
COMPOSE_PROJECT_NAME=interview-system  # Dockeré¡¹ç›®å

# ç«¯å£é…ç½®ï¼ˆå®¿ä¸»æœºç«¯å£ï¼‰
FRONTEND_PORT=80                       # å‰ç«¯ç«¯å£
FRONTEND_HTTPS_PORT=443                # HTTPSç«¯å£
BACKEND_PORT=8080                      # åç«¯APIç«¯å£
REDIS_PORT=6379                        # Redisç«¯å£

# APIé…ç½®ï¼ˆå®¹å™¨å†…éƒ¨ç½‘ç»œï¼‰
VITE_API_BASE_URL=http://interview-backend:3001/api
# è¯´æ˜ï¼šè¿™æ˜¯å‰ç«¯åº”ç”¨å†…éƒ¨è®¿é—®åç«¯çš„URLï¼Œå¿…é¡»èƒ½é€šè¿‡Dockerç½‘ç»œè§£æ

# Dify AIé…ç½®
DIFY_API_KEY=app-xxxxxxxxxxxx          # ä»Difyè·å–
DIFY_API_BASE_URL=https://api.dify.ai/v1
DIFY_WORKFLOW_URL=https://udify.app/workflow/xxx
DIFY_WORKFLOW_SCORE_ID=xxx
DIFY_WORKFLOW_GENERATE_ID=xxx

# Redisé…ç½®
REDIS_HOST=interview-redis             # Redisä¸»æœºï¼ˆå®¹å™¨å†…éƒ¨ï¼‰
REDIS_PASSWORD=                        # å¯†ç ï¼ˆå¦‚æœæœ‰ï¼‰
REDIS_DB=0                             # æ•°æ®åº“ç¼–å·
REDIS_PORT=6379                        # ç«¯å£

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO                         # æ—¥å¿—çº§åˆ«ï¼šDEBUG, INFO, WARN, ERROR
LOG_DIR=/app/logs

# å®‰å…¨é…ç½®
JWT_SECRET=your-super-secret-key       # JWTç­¾åå¯†é’¥ï¼ˆæ”¹ä¸ºå¼ºå¯†ç ï¼‰
JWT_EXPIRATION=86400000                # JWTè¿‡æœŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰

# æ€§èƒ½é…ç½®
MAX_UPLOAD_SIZE=10MB                   # æœ€å¤§ä¸Šä¼ æ–‡ä»¶å¤§å°
RATE_LIMIT_WINDOW=15                   # é™æµæ—¶é—´çª—å£ï¼ˆåˆ†é’Ÿï¼‰
RATE_LIMIT_MAX=100                     # æ—¶é—´çª—å£å†…æœ€å¤§è¯·æ±‚æ•°

# æ—¶åŒºé…ç½®
TZ=Asia/Shanghai                       # æ—¶åŒº
```

### Docker Compose é…ç½®è°ƒä¼˜

```yaml
# æ ¹æ®æœåŠ¡å™¨é…ç½®è°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š

services:
  backend:
    # CPUå’Œå†…å­˜é™åˆ¶
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 512M

  redis:
    command: >
      redis-server
      --maxmemory 512mb        # å¢åŠ ç¼“å­˜å¤§å°
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --appendonly yes

  frontend:
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
```

---

## ç›‘æ§å’Œæ—¥å¿—

### å®æ—¶æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker-compose logs -f

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker-compose logs -f backend
docker-compose logs -f frontend
docker-compose logs -f redis

# æŸ¥çœ‹æœ€å100è¡Œæ—¥å¿—
docker-compose logs --tail=100 backend

# æŸ¥çœ‹ç‰¹å®šæ—¶é—´èŒƒå›´çš„æ—¥å¿—
docker-compose logs --since 10m backend
```

### æ—¥å¿—å­˜å‚¨ä½ç½®

```
logs/
â”œâ”€â”€ backend/          # åç«¯åº”ç”¨æ—¥å¿—
â”‚   â”œâ”€â”€ access.log
â”‚   â”œâ”€â”€ error.log
â”‚   â””â”€â”€ app.log
â”œâ”€â”€ frontend/         # Nginxæ—¥å¿—
â”‚   â”œâ”€â”€ access.log
â”‚   â””â”€â”€ error.log
â”œâ”€â”€ redis/           # Redisæ—¥å¿—
â”‚   â””â”€â”€ redis.log
â””â”€â”€ proxy/           # åå‘ä»£ç†æ—¥å¿—
    â”œâ”€â”€ access.log
    â””â”€â”€ error.log
```

### æ—¥å¿—è½¬å‘è®¾ç½®ï¼ˆELK Stackï¼‰

```yaml
# docker-compose.yml ä¸­çš„æ—¥å¿—é©±åŠ¨é…ç½®

services:
  backend:
    logging:
      driver: "splunk"
      options:
        splunk-token: "your-splunk-token"
        splunk-url: "https://your-splunk-host:8088"
        splunk-insecureskipverify: "true"
        splunk-sourcetype: "docker:backend"
```

### å¥åº·æ£€æŸ¥ç›‘æ§

```bash
# æ£€æŸ¥å®¹å™¨å¥åº·çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹å¥åº·æ£€æŸ¥æ—¥å¿—
docker inspect interview-backend --format='{{json .State.Health}}' | jq

# æ‰‹åŠ¨è§¦å‘å¥åº·æ£€æŸ¥
docker-compose exec backend curl -f http://localhost:3001/api/health
```

---

## å¤‡ä»½å’Œæ¢å¤

### è‡ªåŠ¨å¤‡ä»½ç­–ç•¥

```bash
# åˆ›å»ºå¤‡ä»½è„šæœ¬
cat > backup-prod.sh << 'EOF'
#!/bin/bash

BACKUP_DIR="/opt/interview-system/backups"
BACKUP_TIME=$(date +'%Y%m%d_%H%M%S')
BACKUP_PATH="$BACKUP_DIR/backup_$BACKUP_TIME"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_PATH"

# å¤‡ä»½Redisæ•°æ®
docker-compose exec redis redis-cli BGSAVE
docker cp interview-redis:/data/dump.rdb "$BACKUP_PATH/"

# å¤‡ä»½ä¸Šä¼ æ–‡ä»¶
cp -r backend/uploads "$BACKUP_PATH/"

# å¤‡ä»½æ•°æ®åº“ï¼ˆå¦‚æœæœ‰ï¼‰
# docker-compose exec postgres pg_dump ... > "$BACKUP_PATH/database.sql"

# å‹ç¼©å¤‡ä»½
tar -czf "$BACKUP_PATH.tar.gz" -C "$BACKUP_DIR" "backup_$BACKUP_TIME"

# æ¸…ç†7å¤©å‰çš„å¤‡ä»½
find "$BACKUP_DIR" -name "backup_*" -mtime +7 -delete

echo "å¤‡ä»½å®Œæˆ: $BACKUP_PATH.tar.gz"
EOF

chmod +x backup-prod.sh
```

### å®šæ—¶å¤‡ä»½ï¼ˆCronï¼‰

```bash
# ç¼–è¾‘crontab
crontab -e

# æ·»åŠ æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œå¤‡ä»½
0 2 * * * /opt/interview-system/backup-prod.sh >> /opt/interview-system/backup.log 2>&1

# æŸ¥çœ‹å·²é…ç½®çš„å®šæ—¶ä»»åŠ¡
crontab -l
```

### æ¢å¤æ•°æ®

```bash
# 1. åœæ­¢å®¹å™¨
docker-compose down

# 2. æ¢å¤Redisæ•°æ®
docker cp ./backup_20240101_020000/dump.rdb interview-redis:/data/

# 3. æ¢å¤ä¸Šä¼ æ–‡ä»¶
rm -rf backend/uploads
cp -r ./backup_20240101_020000/uploads backend/

# 4. é‡å¯å®¹å™¨
docker-compose up -d

# 5. éªŒè¯æ•°æ®
docker-compose logs -f
```

### è·¨ä¸»æœºè¿ç§»

```bash
# æºä¸»æœºï¼šåˆ›å»ºå®Œæ•´å¤‡ä»½
tar -czf interview-system-backup.tar.gz \
  docker-compose.yml \
  .env.docker \
  nginx/ \
  logs/ \
  data/ \
  backend/uploads

# ä¼ è¾“åˆ°ç›®æ ‡ä¸»æœº
scp interview-system-backup.tar.gz user@target-host:/tmp/

# ç›®æ ‡ä¸»æœºï¼šè§£å‹å¤‡ä»½
cd /opt/
tar -xzf /tmp/interview-system-backup.tar.gz

# å¯åŠ¨å®¹å™¨
docker-compose up -d
```

---

## æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

#### 1. å®¹å™¨æ— æ³•å¯åŠ¨

```bash
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
docker-compose logs backend

# æ£€æŸ¥é•œåƒæ˜¯å¦æ„å»ºæˆåŠŸ
docker images | grep interview

# é‡æ–°æ„å»ºé•œåƒ
docker-compose build --no-cache

# æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
netstat -tlnp | grep 8080
lsof -i :8080

# è§£å†³æ–¹æ¡ˆï¼šä¿®æ”¹ç«¯å£æˆ–æ€æ­»å ç”¨è¿›ç¨‹
kill -9 <PID>
```

#### 2. Redisè¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥Rediså®¹å™¨çŠ¶æ€
docker-compose ps redis

# æŸ¥çœ‹Redisæ—¥å¿—
docker-compose logs redis

# æµ‹è¯•Redisè¿æ¥
docker-compose exec redis redis-cli ping

# å¦‚æœå¤±è´¥ï¼Œé‡å¯Redis
docker-compose restart redis
```

#### 3. åç«¯æ— æ³•è®¿é—®æ•°æ®åº“

```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker-compose exec backend ping interview-redis

# æ£€æŸ¥Redisè®¤è¯
docker-compose exec redis redis-cli -a <PASSWORD> ping

# æŸ¥çœ‹ç¯å¢ƒå˜é‡
docker-compose exec backend env | grep REDIS
```

#### 4. å‰ç«¯æ— æ³•è¿æ¥åç«¯

```bash
# æ£€æŸ¥åç«¯æœåŠ¡çŠ¶æ€
docker-compose exec backend curl -f http://localhost:3001/api/health

# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker-compose exec frontend curl http://interview-backend:3001/api/health

# æŸ¥çœ‹Nginxé…ç½®
docker-compose exec frontend cat /etc/nginx/nginx.conf

# æ£€æŸ¥CORSé…ç½®
docker-compose logs backend | grep -i cors
```

#### 5. ç£ç›˜ç©ºé—´ä¸è¶³

```bash
# æŸ¥çœ‹ç£ç›˜ä½¿ç”¨
df -h

# æŸ¥çœ‹Dockerå ç”¨ç©ºé—´
docker system df

# æ¸…ç†æœªä½¿ç”¨çš„é•œåƒå’Œå®¹å™¨
docker system prune -a

# æ¸…ç†æœªä½¿ç”¨çš„æ•°æ®å·
docker volume prune

# æ¸…ç†æ—¥å¿—
truncate -s 0 logs/*/*.log
```

### è°ƒè¯•æŠ€å·§

```bash
# è¿›å…¥å®¹å™¨è°ƒè¯•
docker-compose exec backend sh
docker-compose exec frontend sh

# æŸ¥çœ‹å®¹å™¨è¯¦ç»†ä¿¡æ¯
docker inspect interview-backend

# å®æ—¶ç›‘æ§å®¹å™¨èµ„æº
docker stats

# æŸ¥çœ‹å®¹å™¨ç½‘ç»œ
docker network inspect interview-network

# æŠ“å–ç½‘ç»œåŒ…ï¼ˆéœ€è¦tcpdumpï¼‰
docker run --rm --net container:interview-backend \
  -v /tmp:/tmp \
  nicolaka/netshoot tcpdump -i eth0 -w /tmp/backend.pcap
```

---

## å®‰å…¨æœ€ä½³å®è·µ

### 1. ç¯å¢ƒå˜é‡å®‰å…¨

```bash
# âŒ ä¸è¦åšè¿™æ ·çš„äº‹
export DIFY_API_KEY="app-xxxxxxxxxxxx"  # æ˜æ–‡æš´éœ²
git push secrets.env                     # æäº¤æ•æ„Ÿä¿¡æ¯

# âœ… æ­£ç¡®åšæ³•
# 1. ä½¿ç”¨ .env.docker æ–‡ä»¶ï¼ˆæ·»åŠ åˆ° .gitignoreï¼‰
echo ".env.docker" >> .gitignore

# 2. ä½¿ç”¨å¼ºå¯†é’¥
openssl rand -base64 32  # ç”Ÿæˆå¼ºå¯†é’¥
JWT_SECRET=$(openssl rand -base64 32)

# 3. ä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡
# - HashiCorp Vault
# - AWS Secrets Manager
# - Azure Key Vault
```

### 2. é•œåƒå®‰å…¨

```bash
# æ‰«æé•œåƒæ¼æ´
docker scan interview-system/backend
docker scan interview-system/frontend

# ä½¿ç”¨æœ€å°é•œåƒ
# âœ“ alpine (5-50MB)
# âœ“ distroless (10-50MB)
# âœ— ubuntu (77MB)
# âœ— centos (200MB)

# å®šæœŸæ›´æ–°åŸºç¡€é•œåƒ
docker-compose pull

# ä½¿ç”¨ç‰¹å®šç‰ˆæœ¬ï¼ˆè€Œä¸æ˜¯latestï¼‰
FROM node:18.17.0-alpine
FROM nginx:1.25.1-alpine
FROM redis:7.0.12-alpine
```

### 3. ç½‘ç»œå®‰å…¨

```yaml
# docker-compose.yml - éš”ç¦»ç½‘ç»œ

services:
  frontend:
    networks:
      - frontend-only

  backend:
    networks:
      - frontend-backend
      - backend-redis

  redis:
    networks:
      - backend-redis

networks:
  frontend-only:
    driver: bridge
  frontend-backend:
    driver: bridge
  backend-redis:
    driver: bridge
```

### 4. è®¿é—®æ§åˆ¶

```bash
# Rediså¯†ç ä¿æŠ¤
# åœ¨ docker-compose.yml ä¸­ï¼š
redis:
  command: redis-server --requirepass "your-strong-password"

# è¿æ¥æ—¶ä½¿ç”¨å¯†ç 
docker-compose exec redis redis-cli -a "your-strong-password" ping
```

### 5. æ—¥å¿—å®¡è®¡

```bash
# å¯ç”¨Dockeræ—¥å¿—é©±åŠ¨
logging:
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"
    labels: "service=backend,env=production"

# å®šæœŸå®¡æŸ¥æ—¥å¿—
docker-compose logs backend | grep ERROR
docker-compose logs backend | grep -i "unauthorized"
```

### 6. å®¹å™¨ç”¨æˆ·æƒé™

```dockerfile
# ä»¥érootç”¨æˆ·è¿è¡Œ
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodeuser -u 1001

USER nodeuser
```

### 7. å®šæœŸæ›´æ–°

```bash
# æ¯æœˆæ›´æ–°åŸºç¡€é•œåƒ
docker pull node:18-alpine
docker pull nginx:alpine
docker pull redis:7-alpine

# é‡æ–°æ„å»ºå¹¶æµ‹è¯•
docker-compose build --no-cache
docker-compose up -d

# æ£€æŸ¥å˜æ›´æ—¥å¿—
docker images --digests
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. Redisä¼˜åŒ–

```conf
# æœ€å¤§å†…å­˜ç®¡ç†
maxmemory 512mb              # æ ¹æ®å¯ç”¨å†…å­˜è°ƒæ•´
maxmemory-policy allkeys-lru # LRUé©±é€ç­–ç•¥

# æŒä¹…åŒ–ä¼˜åŒ–
save 900 1                   # 900ç§’å†…è‡³å°‘1ä¸ªkeyå˜åŒ–åˆ™ä¿å­˜
save 300 10                  # 300ç§’å†…è‡³å°‘10ä¸ªkeyå˜åŒ–åˆ™ä¿å­˜
save 60 10000                # 60ç§’å†…è‡³å°‘10000ä¸ªkeyå˜åŒ–åˆ™ä¿å­˜

appendonly yes               # å¯ç”¨AOFæŒä¹…åŒ–
appendfsync everysec         # æ¯ç§’åŒæ­¥ä¸€æ¬¡
```

### 2. Nginxä¼˜åŒ–

```nginx
# è¿æ¥ä¼˜åŒ–
worker_connections 2048;
keepalive_timeout 65;
keepalive_requests 100;

# ç¼“å­˜ä¼˜åŒ–
proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:10m;
proxy_cache_valid 200 1h;
proxy_cache_valid 404 1m;

# å‹ç¼©ä¼˜åŒ–
gzip on;
gzip_min_length 1000;
gzip_types text/plain text/css text/javascript application/json;

# è´Ÿè½½å‡è¡¡
upstream backend {
    least_conn;
    server interview-backend-1:3001;
    server interview-backend-2:3001;
    server interview-backend-3:3001;
}
```

### 3. Node.js ä¼˜åŒ–

```javascript
// è®¾ç½®ç¯å¢ƒå˜é‡
process.env.NODE_ENV = 'production';

// ä½¿ç”¨é›†ç¾¤æ¨¡å¼
const cluster = require('cluster');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }
}

// å†…å­˜ä¼˜åŒ–
--max-old-space-size=2048
--enable-source-maps
```

### 4. æ•°æ®åº“è¿æ¥æ± 

```javascript
// è¿æ¥æ± é…ç½®
const pool = {
  max: 20,              // æœ€å¤§è¿æ¥æ•°
  min: 5,               // æœ€å°è¿æ¥æ•°
  acquireTimeoutMillis: 30000,
  idleTimeoutMillis: 30000,
  reapIntervalMillis: 1000
};
```

### 5. CDNé›†æˆ

```nginx
# åœ¨Nginxä¸­é…ç½®CDNæºç«™
upstream cdn {
    server cdn.example.com;
}

location /static/ {
    proxy_pass http://cdn;
    proxy_cache_valid 200 30d;
    add_header X-Cache-Status $upstream_cache_status;
}
```

---

## ç›‘æ§å’Œå‘Šè­¦

### Prometheusç›‘æ§è®¾ç½®

```yaml
# docker-compose.yml æ·»åŠ 

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - interview-network

  grafana:
    image: grafana/grafana:latest
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin
    ports:
      - "3000:3000"
    networks:
      - interview-network
    depends_on:
      - prometheus
```

### å…³é”®æŒ‡æ ‡ç›‘æ§

```yaml
# prometheus.yml

global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'docker'
    static_configs:
      - targets: ['localhost:9323']

  - job_name: 'backend'
    static_configs:
      - targets: ['interview-backend:3001']

  - job_name: 'redis'
    static_configs:
      - targets: ['interview-redis:6379']
```

---

## å‡çº§å’Œå›æ»š

### å®‰å…¨å‡çº§æµç¨‹

```bash
# 1. åˆ›å»ºå®Œæ•´å¤‡ä»½
./backup-prod.sh

# 2. åœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯æ–°ç‰ˆæœ¬
docker-compose -f docker-compose.test.yml up

# 3. æ‹‰å–æ–°é•œåƒ
docker-compose pull

# 4. åœæ­¢æ—§å®¹å™¨
docker-compose down

# 5. å¯åŠ¨æ–°å®¹å™¨
docker-compose up -d

# 6. éªŒè¯æ–°ç‰ˆæœ¬
docker-compose ps
docker-compose logs -f

# 7. å¥åº·æ£€æŸ¥
curl http://localhost:80
curl http://localhost:8080/api/health
```

### å¿«é€Ÿå›æ»š

```bash
# å¦‚æœå‡ºç°é—®é¢˜ï¼Œå¿«é€Ÿå›æ»š
docker-compose down

# æ¢å¤å¤‡ä»½
cp -r ./backup_20240101_020000/* ./

# é‡å¯æœåŠ¡
docker-compose up -d
```

---

## æˆæœ¬ä¼˜åŒ–

### é•œåƒå¤§å°ä¼˜åŒ–

```dockerfile
# å¤šé˜¶æ®µæ„å»ºï¼Œå‡å°æœ€ç»ˆé•œåƒå¤§å°

# æ„å»ºé˜¶æ®µ
FROM node:18-alpine AS builder
WORKDIR /app
COPY . .
RUN npm install && npm run build

# ç”Ÿäº§é˜¶æ®µ
FROM node:18-alpine
WORKDIR /app
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
CMD ["npm", "start"]
```

### èµ„æºé™åˆ¶

```yaml
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '2'      # é™åˆ¶CPUä½¿ç”¨
          memory: 1G     # é™åˆ¶å†…å­˜ä½¿ç”¨
        reservations:
          cpus: '1'
          memory: 512M
```

---

## æ–‡æ¡£å’Œæ”¯æŒ

- å®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.docker.com
- Dockeræœ€ä½³å®è·µï¼šhttps://docs.docker.com/develop/dev-best-practices/
- Difyæ–‡æ¡£ï¼šhttps://docs.dify.ai

---

## ç‰ˆæœ¬å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | å˜æ›´ |
|------|------|------|
| 1.0 | 2024-01-01 | åˆå§‹ç‰ˆæœ¬ |

---

## è®¸å¯è¯

MIT License

---

**æœ€åæ›´æ–°**: 2024-01-01
**ç»´æŠ¤è€…**: AIé¢è¯•ç³»ç»Ÿå›¢é˜Ÿ
